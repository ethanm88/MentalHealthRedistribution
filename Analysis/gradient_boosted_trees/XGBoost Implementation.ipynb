{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Decision Tree Classifier Assignment\n",
    "## By: Patrick Liu 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Background on The Dataset\n",
    "- This dataset is pertained to mental health as well. In this case, an organization called OSMI (open sourcing mental illness), is a nonprofit organization committed to using technology and open source software to improve the mental health of those in tech-related jobs.\n",
    "    - They conduct a yearly survey that asks people in tech all kinds of qusetions related to their mental health in the context of their tech job that they are working as well as the support that they have received/not received.\n",
    "    - This dataset is the collection of responses to this survery from 2014-2019!\n",
    "\n",
    "# What is Our Goal?\n",
    "- Predict if a person has sought treatment for any mental health issue given their responses to the survey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Company Size</th>\n",
       "      <th>year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age-Group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sought Treatment</th>\n",
       "      <th>Describe Past Experience</th>\n",
       "      <th>Prefer Anonymity</th>\n",
       "      <th>Rate Reaction to Problems</th>\n",
       "      <th>Negative Consequences</th>\n",
       "      <th>Location</th>\n",
       "      <th>Access to information</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Discuss Mental Health Problems</th>\n",
       "      <th>Responsible Employer</th>\n",
       "      <th>Disorder Notes</th>\n",
       "      <th>Disorder</th>\n",
       "      <th>Primarily a Tech Employer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>6-25</td>\n",
       "      <td>2014</td>\n",
       "      <td>37</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>More than 1000</td>\n",
       "      <td>2014</td>\n",
       "      <td>44</td>\n",
       "      <td>41-65</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>6-25</td>\n",
       "      <td>2014</td>\n",
       "      <td>32</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>26-100</td>\n",
       "      <td>2014</td>\n",
       "      <td>31</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>100-500</td>\n",
       "      <td>2014</td>\n",
       "      <td>31</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Family History of Mental Illness    Company Size  year  Age Age-Group  \\\n",
       "0                               No            6-25  2014   37     31-40   \n",
       "1                               No  More than 1000  2014   44     41-65   \n",
       "2                               No            6-25  2014   32     31-40   \n",
       "3                              Yes          26-100  2014   31     31-40   \n",
       "4                               No         100-500  2014   31     31-40   \n",
       "\n",
       "   Gender  Sought Treatment Describe Past Experience  Prefer Anonymity  \\\n",
       "0  Female                 1                      NaN               NaN   \n",
       "1    Male                 0                      NaN               NaN   \n",
       "2    Male                 0                      NaN               NaN   \n",
       "3    Male                 1                      NaN               NaN   \n",
       "4    Male                 0                      NaN               NaN   \n",
       "\n",
       "  Rate Reaction to Problems Negative Consequences        Location  \\\n",
       "0                       NaN                    No             USA   \n",
       "1                       NaN                 Maybe             USA   \n",
       "2                       NaN                    No          Canada   \n",
       "3                       NaN                   Yes  United Kingdom   \n",
       "4                       NaN                    No             USA   \n",
       "\n",
       "   Access to information  Insurance Diagnosis Discuss Mental Health Problems  \\\n",
       "0                      1        NaN       NaN                          Maybe   \n",
       "1                      0        NaN       NaN                             No   \n",
       "2                      0        NaN       NaN                            Yes   \n",
       "3                      0        NaN       NaN                          Maybe   \n",
       "4                      0        NaN       NaN                          Maybe   \n",
       "\n",
       "  Responsible Employer Disorder Notes  Disorder  Primarily a Tech Employer  \n",
       "0                  Yes            NaN         0                        1.0  \n",
       "1                   No            NaN         0                        0.0  \n",
       "2                   No            NaN         0                        1.0  \n",
       "3                   No            NaN         0                        1.0  \n",
       "4                   No            NaN         0                        1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OSMIcleaned.csv')\n",
    "# preview data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a lot of invalid values (look at the NaNs), so we are going to have to do some preprocessing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fill in NaN values\n",
    "def bestFill(dataset):\n",
    "    for feature in dataset:\n",
    "        if dataset[feature].dtype == np.int64:\n",
    "             dataset[feature] = pd.to_numeric(dataset[feature], errors='coerce').astype(int)\n",
    "             dataset[feature].fillna(-1, inplace=True)\n",
    " \n",
    "        elif dataset[feature].dtype == np.float64:\n",
    "             dataset[feature].fillna(-1, inplace=True)\n",
    "             dataset[feature] = pd.to_numeric(dataset[feature], errors='coerce').astype(float)\n",
    "\n",
    "        elif dataset[feature].dtype == np.object:\n",
    "             dataset[feature].fillna('NaN', inplace=True)\n",
    "bestFill(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features we will use to predict y\n",
    "X = data.drop(['Sought Treatment', 'Describe Past Experience', 'Location', 'Disorder Notes'], axis = 1)\n",
    "# what we will predict\n",
    "y= data['Sought Treatment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding/Scaling Features\n",
    "- Why do we scale data?\n",
    "    - to normalize data within a certain range\n",
    "    - we will scale our numerical features\n",
    "- Why do we encode data?\n",
    "    - Because numbers are easier to work with 8)\n",
    "    - we will encode our categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = (X.dtypes == 'float') | (X.dtypes == 'int')\n",
    "categorical_features = ~numerical_features\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), numerical_features),\n",
    "    (OneHotEncoder(), categorical_features), remainder=\"drop\", n_jobs= -1, verbose = True\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.40, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "- If you want to learn what these metrics mean, I would take a look at sklearn.metrics documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def evaluateModel(model, yPredClass, plot=False):\n",
    "    # Classification Accuracy: Overall, how often is the classifier correct?\n",
    "    accuracy = metrics.accuracy_score(Y_test, yPredClass)\n",
    "    print('Classification Accuracy:', accuracy*100)\n",
    "    \n",
    "    # Comparing the true and predicted response values\n",
    "    print('True:', Y_test.values[0:25])\n",
    "    print('Pred:', yPredClass[0:25])\n",
    "   \n",
    "    # Metrics computed from a confusion matrix\n",
    "    confusion = metrics.confusion_matrix(Y_test, yPredClass)\n",
    "    TP = confusion[1, 1]   # True Positive\n",
    "    TN = confusion[0, 0]   # True Negative\n",
    "    FP = confusion[0, 1]   # False Positive\n",
    "    FN = confusion[1, 0]   # False Negative\n",
    "    \n",
    "    # False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "    false_positive_rate = FP / float(FP+TN)\n",
    "    print('False Positive Rate:', false_positive_rate)\n",
    "\n",
    "    # Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "    print('Precision:', metrics.precision_score(Y_test, yPredClass))\n",
    "\n",
    "#     # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "#     print('AUC Score:', metrics.roc_auc_score(Y_test, yPredClass))\n",
    "#     # store the predicted probabilities for class 1\n",
    "#     y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#     # visualize Confusion Matrix\n",
    "#     fig = sns.heatmap(confusion, annot=True, fmt=\"d\")\n",
    "#     bottom, top = fig.get_ylim()\n",
    "#     fig.set_ylim(bottom + 0.5, top - 0.5)\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('Actual')\n",
    "#     plt.show()\n",
    "    \n",
    "#     # histogram of predicted probabilities\n",
    "#     if plot:\n",
    "#         plt.rcParams['font.size'] = 12\n",
    "#         plt.hist(y_pred_prob, bins=4)\n",
    "#         # x-axis limit from 0 to 1\n",
    "#         plt.xlim(0, 1)\n",
    "#         plt.title('Histogram of predicted probabilities')\n",
    "#         plt.xlabel('Predicted probability of treatment')\n",
    "#         plt.ylabel('Frequency')\n",
    "\n",
    "#     # AUC is the percentage of the ROC plot that is underneath the curve\n",
    "#     # Higher value = better classifier\n",
    "#     roc_auc = metrics.roc_auc_score(Y_test, y_pred_prob)\n",
    "\n",
    "#     # roc_curve returns 3 objects fpr, tpr, thresholds\n",
    "#     # fpr: false positive rate\n",
    "#     # tpr: true positive rate\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_prob)\n",
    "#     if plot:\n",
    "#         plt.figure()\n",
    "#         plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "#         plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "#         plt.xlim([0.0, 1.0])\n",
    "#         plt.ylim([0.0, 1.0])\n",
    "#         plt.rcParams['font.size'] = 12\n",
    "#         plt.title('ROC curve for treatment classifier')\n",
    "#         plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "#         plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "#         plt.legend(loc=\"lower right\")\n",
    "#         plt.show()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Models!\n",
    "- To give you guys some help, I've trained a model using Logistic Regression. The process for training an XgBoost classifier should be very similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Logistic Regression ###############\n",
      "Classification Accuracy: 80.86492890995261\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18549511854951187\n",
      "Precision: 0.8544857768052516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def logisticRegression():\n",
    "    modelLogisticRegression = make_pipeline(preprocess, LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "    modelLogisticRegression.fit(X_train, Y_train)\n",
    "\n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = modelLogisticRegression.predict(X_test)\n",
    "\n",
    "    print('############### Logistic Regression ###############')\n",
    "\n",
    "    accuracy_score = evaluateModel(modelLogisticRegression, y_pred_class, True)\n",
    "    \n",
    "    \n",
    "logisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now it's your turn to implement your own XGBoost Classifier!\n",
    "Some notes:\n",
    "- Run `pip install xgboost` to get the xgboost package\n",
    "- Once you are done training, try evaluating the accuracy of your model using the `evaluateModel` function above and with the test dataset. This model should be more accurate than the Logistic Regression classifier.\n",
    "- try playing around with tuning the parameters to get the highest accuracy possible!\n",
    "    - in particular, try tuning the `eta` and `max_depth` parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 79.85781990521326\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.16596931659693165\n",
      "Precision: 0.8630609896432682\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 79.85781990521326\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.16736401673640167\n",
      "Precision: 0.8622273249138921\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 80.62796208530806\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.17294281729428174\n",
      "Precision: 0.8609865470852018\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 80.62796208530806\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.17852161785216178\n",
      "Precision: 0.8577777777777778\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 80.39099526066352\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.1799163179916318\n",
      "Precision: 0.856347438752784\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 80.45023696682463\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18828451882845187\n",
      "Precision: 0.8518111964873765\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 80.6872037914692\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18688981868898186\n",
      "Precision: 0.8532311062431545\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 80.80568720379146\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18688981868898186\n",
      "Precision: 0.853551912568306\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 80.80568720379146\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.19246861924686193\n",
      "Precision: 0.8504875406283857\n",
      "\n",
      "##### MAX DEPTH 3, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 81.22037914691943\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18410041841004185\n",
      "Precision: 0.8562091503267973\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 79.68009478672985\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18410041841004185\n",
      "Precision: 0.852017937219731\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 80.74644549763033\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.16736401673640167\n",
      "Precision: 0.8645598194130926\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 80.74644549763033\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.1799163179916318\n",
      "Precision: 0.8573008849557522\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 81.10189573459715\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.17712691771269176\n",
      "Precision: 0.8598233995584988\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 81.27962085308057\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18270571827057183\n",
      "Precision: 0.8571428571428571\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 81.51658767772511\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18549511854951187\n",
      "Precision: 0.8562162162162162\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 81.69431279620854\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18688981868898186\n",
      "Precision: 0.8559139784946237\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 80.92417061611374\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0]\n",
      "False Positive Rate: 0.19386331938633194\n",
      "Precision: 0.8500539374325782\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 80.98341232227489\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.199442119944212\n",
      "Precision: 0.8472222222222222\n",
      "\n",
      "##### MAX DEPTH 4, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 80.50947867298578\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.20223152022315202\n",
      "Precision: 0.8444206008583691\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 80.03554502369668\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.17852161785216178\n",
      "Precision: 0.8561797752808988\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 80.80568720379146\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18270571827057183\n",
      "Precision: 0.8558855885588559\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 81.10189573459715\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18549511854951187\n",
      "Precision: 0.855119825708061\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 80.98341232227489\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.19386331938633194\n",
      "Precision: 0.8502155172413793\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 81.1611374407583\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.1896792189679219\n",
      "Precision: 0.8529729729729729\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 81.04265402843602\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.19386331938633194\n",
      "Precision: 0.8503767491926802\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 81.10189573459715\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.200836820083682\n",
      "Precision: 0.8468085106382979\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 80.33175355450237\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.20641562064156208\n",
      "Precision: 0.841711229946524\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 80.03554502369668\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2175732217573222\n",
      "Precision: 0.8350951374207188\n",
      "\n",
      "##### MAX DEPTH 5, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 79.91706161137441\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2175732217573222\n",
      "Precision: 0.8347457627118644\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.01 #####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 79.79857819905213\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0]\n",
      "False Positive Rate: 0.20502092050209206\n",
      "Precision: 0.8409090909090909\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 80.74644549763033\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.18828451882845187\n",
      "Precision: 0.8526200873362445\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 80.50947867298578\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.19525801952580196\n",
      "Precision: 0.8481561822125814\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 80.74644549763033\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.19246861924686193\n",
      "Precision: 0.8503253796095445\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 80.33175355450237\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.19804741980474197\n",
      "Precision: 0.8461538461538461\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 79.97630331753555\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21199442119944212\n",
      "Precision: 0.8377801494130203\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 79.56161137440758\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22315202231520223\n",
      "Precision: 0.8308668076109936\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 79.4431279620853\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2175732217573222\n",
      "Precision: 0.8333333333333334\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 78.73222748815166\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23709902370990238\n",
      "Precision: 0.8214285714285714\n",
      "\n",
      "##### MAX DEPTH 6, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 78.9691943127962\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22315202231520223\n",
      "Precision: 0.8290598290598291\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 79.4431279620853\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21478382147838215\n",
      "Precision: 0.8347639484978541\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 80.15402843601895\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.200836820083682\n",
      "Precision: 0.8441558441558441\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 79.68009478672985\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2105997210599721\n",
      "Precision: 0.8376344086021505\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 79.97630331753555\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21478382147838215\n",
      "Precision: 0.8363443145589798\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 79.56161137440758\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21478382147838215\n",
      "Precision: 0.8351177730192719\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 79.32464454976304\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2203626220362622\n",
      "Precision: 0.8315565031982942\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 78.7914691943128\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2203626220362622\n",
      "Precision: 0.829924650161464\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 78.49526066350711\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22873082287308227\n",
      "Precision: 0.8247863247863247\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 77.8436018957346\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2482566248256625\n",
      "Precision: 0.8132214060860441\n",
      "\n",
      "##### MAX DEPTH 7, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 78.08056872037915\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23709902370990238\n",
      "Precision: 0.8193411264612115\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 78.67298578199052\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22454672245467225\n",
      "Precision: 0.827438370846731\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 79.62085308056872\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.200836820083682\n",
      "Precision: 0.8426229508196721\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 79.56161137440758\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.20781032078103207\n",
      "Precision: 0.8387445887445888\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 79.32464454976304\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2175732217573222\n",
      "Precision: 0.8329764453961456\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 79.4431279620853\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22315202231520223\n",
      "Precision: 0.8305084745762712\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 78.55450236966824\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2398884239888424\n",
      "Precision: 0.8195173137460651\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 78.25829383886256\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2315202231520223\n",
      "Precision: 0.8226495726495726\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 78.37677725118483\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23430962343096234\n",
      "Precision: 0.821656050955414\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 78.3175355450237\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22733612273361228\n",
      "Precision: 0.8249194414607949\n",
      "\n",
      "##### MAX DEPTH 8, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 78.13981042654028\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23570432357043236\n",
      "Precision: 0.8202127659574469\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.01 #####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 78.7914691943128\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2301255230125523\n",
      "Precision: 0.8250265111346765\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 79.62085308056872\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21617852161785217\n",
      "Precision: 0.8345784418356457\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 79.68009478672985\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21617852161785217\n",
      "Precision: 0.8347547974413646\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 78.67298578199052\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2203626220362622\n",
      "Precision: 0.8295577130528586\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 78.73222748815166\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22733612273361228\n",
      "Precision: 0.826226012793177\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 78.43601895734598\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22873082287308227\n",
      "Precision: 0.8245989304812834\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 78.02132701421802\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22733612273361228\n",
      "Precision: 0.8239740820734341\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 78.9691943127962\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2301255230125523\n",
      "Precision: 0.8255813953488372\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 78.08056872037915\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2384937238493724\n",
      "Precision: 0.8186638388123012\n",
      "\n",
      "##### MAX DEPTH 9, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 77.90284360189574\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23430962343096234\n",
      "Precision: 0.8201284796573876\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 78.7914691943128\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22873082287308227\n",
      "Precision: 0.8257173219978746\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 79.02843601895735\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2175732217573222\n",
      "Precision: 0.8320775026910656\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 78.85071090047393\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2217573221757322\n",
      "Precision: 0.8293991416309013\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 77.8436018957346\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22733612273361228\n",
      "Precision: 0.8234019501625135\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 78.90995260663507\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2175732217573222\n",
      "Precision: 0.8317152103559871\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 78.25829383886256\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22315202231520223\n",
      "Precision: 0.8268398268398268\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 78.49526066350711\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21617852161785217\n",
      "Precision: 0.8311546840958606\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 77.60663507109004\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2315202231520223\n",
      "Precision: 0.8205405405405405\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 77.66587677725119\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23709902370990238\n",
      "Precision: 0.8179871520342612\n",
      "\n",
      "##### MAX DEPTH 10, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 77.60663507109004\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2384937238493724\n",
      "Precision: 0.8171122994652407\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.01 #####\n",
      "Classification Accuracy: 77.96208530805687\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2384937238493724\n",
      "Precision: 0.8182784272051009\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 78.67298578199052\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21896792189679218\n",
      "Precision: 0.8302702702702702\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 78.37677725118483\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22315202231520223\n",
      "Precision: 0.8272138228941684\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 78.43601895734598\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21896792189679218\n",
      "Precision: 0.8295331161780674\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 78.08056872037915\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.21896792189679218\n",
      "Precision: 0.8284153005464481\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 78.43601895734598\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22454672245467225\n",
      "Precision: 0.8266953713670614\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 77.78436018957346\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23570432357043236\n",
      "Precision: 0.8190578158458244\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 77.60663507109004\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2315202231520223\n",
      "Precision: 0.8205405405405405\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 78.02132701421802\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23430962343096234\n",
      "Precision: 0.8205128205128205\n",
      "\n",
      "##### MAX DEPTH 11, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 77.31042654028435\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2412831241283124\n",
      "Precision: 0.8147751605995718\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.01 #####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 77.96208530805687\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.24546722454672246\n",
      "Precision: 0.814931650893796\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.03 #####\n",
      "Classification Accuracy: 78.19905213270142\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22733612273361228\n",
      "Precision: 0.8245425188374597\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.05 #####\n",
      "Classification Accuracy: 78.3175355450237\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22873082287308227\n",
      "Precision: 0.8242229367631297\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.07 #####\n",
      "Classification Accuracy: 78.13981042654028\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22454672245467225\n",
      "Precision: 0.8257575757575758\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.09 #####\n",
      "Classification Accuracy: 78.08056872037915\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22873082287308227\n",
      "Precision: 0.8234660925726588\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.11 #####\n",
      "Classification Accuracy: 77.72511848341233\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2315202231520223\n",
      "Precision: 0.8209277238403452\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.13 #####\n",
      "Classification Accuracy: 78.19905213270142\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.22315202231520223\n",
      "Precision: 0.8266522210184182\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.15 #####\n",
      "Classification Accuracy: 77.42890995260665\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.24407252440725244\n",
      "Precision: 0.8138297872340425\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.17 #####\n",
      "Classification Accuracy: 77.96208530805687\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.23430962343096234\n",
      "Precision: 0.8203208556149733\n",
      "\n",
      "##### MAX DEPTH 12, Learning Rate 0.19 #####\n",
      "Classification Accuracy: 77.72511848341233\n",
      "True: [1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "False Positive Rate: 0.2398884239888424\n",
      "Precision: 0.8168264110756124\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "results_table = []\n",
    "x = []\n",
    "y = []\n",
    "z = np.zeros((10,10))\n",
    "############################ TODO ############################\n",
    "# def xgBoost():\n",
    "#     max_depth = 3;\n",
    "#     for i in range(10):\n",
    "#         learning_rate = 0.01\n",
    "#         for i in range(10):\n",
    "#             print('\\n##### MAX DEPTH ' + str(max_depth) + \", Learning Rate \" + str(learning_rate) + \" #####\")\n",
    "#             grid = {'max_depth':max_depth, 'learning_rate':learning_rate}\n",
    "#             clf = XGBClassifier()\n",
    "#             clf.set_params(**grid)\n",
    "\n",
    "#             modelXGBoost = make_pipeline(preprocess, clf)\n",
    "#             modelXGBoost.fit(X_train, Y_train)\n",
    "#             preds = modelXGBoost.predict(X_test)\n",
    "            \n",
    "#             accuracy_score = evaluateModel(modelXGBoost, preds, True)\n",
    "#             results_table.append([max_depth, learning_rate, accuracy_score])\n",
    "#             x.append(max_depth)\n",
    "#             y.append(learning_rate)\n",
    "#             z.append(accuracy_score)\n",
    "            \n",
    "#             learning_rate += 0.02\n",
    "\n",
    "#         max_depth += 1\n",
    "\n",
    "def xgBoost(max_depth, learning_rate, xin, yin):\n",
    "    grid = {'max_depth':max_depth, 'learning_rate':learning_rate}\n",
    "    clf = XGBClassifier()\n",
    "    clf.set_params(**grid)\n",
    "\n",
    "    modelXGBoost = make_pipeline(preprocess, clf)\n",
    "    modelXGBoost.fit(X_train, Y_train)\n",
    "    preds = modelXGBoost.predict(X_test)\n",
    "\n",
    "    accuracy_score = evaluateModel(modelXGBoost, preds, True)\n",
    "    results_table.append([max_depth, learning_rate, accuracy_score])\n",
    "    x.append(max_depth)\n",
    "    y.append(learning_rate)\n",
    "    z.itemset((xin, yin), accuracy_score*100)\n",
    "\n",
    "max_depth = 3\n",
    "for i in range(10):\n",
    "    learning_rate = 0.01\n",
    "    for j in range(10):\n",
    "        print('\\n##### MAX DEPTH ' + str(max_depth) + \", Learning Rate \" + str(round(learning_rate,2)) + \" #####\")\n",
    "        xgBoost(max_depth, learning_rate, 9-j, i)\n",
    "        learning_rate += 0.02\n",
    "    max_depth += 1\n",
    "\n",
    "N = int(len(z)**.5)\n",
    "z = np.array(z)\n",
    "plt.imshow(z, extent=(np.amin(x), np.amax(x), np.amin(y), np.amax(y)), norm=LogNorm(), aspect = 'auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# print('\\n##### MAX DEPTH ' + str(4) + \", Learning Rate \" + str(0.13) + \" #####\")\n",
    "# xgBoost(4, 0.13, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
